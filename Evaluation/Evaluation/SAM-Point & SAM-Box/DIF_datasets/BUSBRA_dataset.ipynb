{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEPDo2IMThEqS6WjX1F4bV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"o4pE8CEJzz2Z"},"outputs":[],"source":["# import drive files\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["using_colab = True\n","if using_colab:\n","    import torch\n","    import torchvision\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything-2.git'"],"metadata":{"id":"ytajzkJOz11s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Mexico TEST\n"," image_folder = '/content/drive/MyDrive/mexico_dataset/labels'  # path of all the test images\n"," gt_folder = '/content/drive/MyDrive/mexico_dataset/masks'  # path of ground truth masks\n"," result_folder = '/content/drive/MyDrive/trabalho/SAM2/BUS_all_dataset_resize/test/results' # path of evaluation result images\n"," sam2_checkpoint = \"/content/drive/MyDrive/sam2_hiera_large.pt\"  #checkpoints (coefficients) of the SAM2 model\n","\n"," model_cfg = \"sam2_hiera_l.yaml\""],"metadata":{"id":"qVZLwXSCz14F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# if using Apple MPS, fall back to CPU for unsupported ops\n","os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pandas as pd\n","import random\n","from sam2.build_sam import build_sam2\n","from sam2.sam2_image_predictor import SAM2ImagePredictor\n","\n","# select the device for computation\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    current_device = torch.cuda.current_device()\n","    print(\"Current GPU device:\", torch.cuda.get_device_name(current_device))\n","elif torch.backends.mps.is_available():\n","    device = torch.device(\"mps\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(f\"using device: {device}\")\n","\n","if device.type == \"cuda\":\n","    # use bfloat16 for the entire notebook\n","    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n","    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n","    if torch.cuda.get_device_properties(0).major >= 8:\n","        torch.backends.cuda.matmul.allow_tf32 = True\n","        torch.backends.cudnn.allow_tf32 = True\n","elif device.type == \"mps\":\n","    print(\n","        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n","        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n","        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n","    )\n","\n","# Define functions\n","np.random.seed(3)\n","\n","def show_anns(anns, borders=True):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","\n","    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n","    img[:, :, 3] = 0\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        color_mask = np.concatenate([np.random.random(3), [0.5]])\n","        img[m] = color_mask\n","        if borders:\n","            import cv2\n","            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n","            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)\n","    ax.imshow(img)\n","\n","def show_mask(mask, ax, random_color=False, borders=True):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask = mask.astype(np.uint8)\n","    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    if borders:\n","        import cv2\n","        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n","        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2)\n","    ax.imshow(mask_image)\n","\n","def show_points(coords, labels, ax, marker_size=375):\n","    pos_points = coords[labels==1]\n","    neg_points = coords[labels==0]\n","    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","    ax.scatter(neg_points[:, 0], coords[labels==0][:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","\n","def show_box(box, ax):\n","    x0, y0 = box[0], box[1]\n","    w, h = box[2] - box[0], box[3] - box[1]\n","    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))\n","\n","def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n","    for i, (mask, score) in enumerate(zip(masks, scores)):\n","        plt.figure(figsize=(5, 5))\n","        plt.imshow(image)\n","        show_mask(mask, plt.gca(), borders=borders)\n","        if point_coords is not None:\n","            assert input_labels is not None\n","            show_points(point_coords, input_labels, plt.gca())\n","        if box_coords is not None:\n","            show_box(box_coords, plt.gca())\n","        if len(scores) > 1:\n","            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n","        plt.axis('off')\n","        plt.show()\n","\n","def threshold_mask(probability_mask, threshold=0.5):\n","    return (probability_mask >= threshold).astype(int)\n","\n","def dice_coefficient(pred_mask, true_mask):\n","    intersection = np.sum(pred_mask * true_mask)\n","    return (2. * intersection) / (np.sum(pred_mask) + np.sum(true_mask))\n","\n","def calculate_iou(binary_mask1, binary_mask2):\n","    intersection = np.logical_and(binary_mask1, binary_mask2).sum()\n","    union = np.logical_or(binary_mask1, binary_mask2).sum()\n","    return 1.0 if union == 0 else intersection / union\n","\n","def find_median_point(gt):\n","    \"\"\"\n","    Finds the median point of all white pixels (foreground region of the mask).\n","\n","    gt: binary mask (numpy array)\n","\n","    Returns:\n","    median_x, median_y: coordinates of the median point\n","    \"\"\"\n","    white_pixels = np.column_stack(np.where(gt == 1))\n","\n","    if len(white_pixels) > 0:\n","        median_x = np.median(white_pixels[:, 0]).astype(int)\n","        median_y = np.median(white_pixels[:, 1]).astype(int)\n","\n","        if gt[median_x, median_y] == 1:\n","            return median_x, median_y\n","        else:\n","            print(\"The computed median is not in the white region. Selecting the closest point.\")\n","            closest_idx = np.argmin(np.linalg.norm(white_pixels - np.array([median_x, median_y]), axis=1))\n","            closest_point = white_pixels[closest_idx]\n","            return closest_point[0], closest_point[1]\n","    else:\n","        raise ValueError(\"No white pixels found in the mask.\")\n","\n","def find_rect_box(gt):\n","    white_pixels = np.column_stack(np.where(gt == 1))\n","    if len(white_pixels) > 0:\n","        x_min, y_min = np.min(white_pixels, axis=0)\n","        x_max, y_max = np.max(white_pixels, axis=0)\n","    else:\n","        print(\"Invalid mask\")\n","    input_box = np.array([y_min, x_min, y_max, x_max])\n","    return input_box\n","\n","def segment(prompt_type, prompt, image_path, predictor=None, show_mask=False):\n","    if predictor is None:\n","        raise ValueError(\"Predictor must be initialized before calling segment function\")\n","\n","    image = Image.open(image_path)\n","    image = np.array(image.convert(\"RGB\"))\n","    predictor.set_image(image)\n","\n","    if prompt_type == 1:  # single point\n","        input_label = np.array([1])\n","        masks, scores, _ = predictor.predict(\n","            point_coords=prompt,\n","            point_labels=input_label,\n","            multimask_output=False,\n","        )\n","        pred_mask = threshold_mask(masks)\n","        if show_mask:\n","            show_masks(image, masks, scores, point_coords=input_point, input_labels=input_label, borders=True)\n","    elif prompt_type == 2:  # single box\n","        masks, scores, _ = predictor.predict(\n","            point_coords=None,\n","            point_labels=None,\n","            box=prompt[None, :],\n","            multimask_output=False,\n","        )\n","        pred_mask = threshold_mask(masks)\n","        if show_mask:\n","            show_masks(image, masks, scores, box_coords=input_box)\n","    return pred_mask\n"],"metadata":{"id":"3sh3U9ECz16l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sam2_model = build_sam2(model_cfg, sam2_checkpoint, device=device)\n","predictor = SAM2ImagePredictor(sam2_model)"],"metadata":{"id":"wZZGrm9pz19L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["SAM Point"],"metadata":{"id":"oQL5QUgIz9jL"}},{"cell_type":"code","source":["import os\n","import numpy as np\n","from PIL import Image\n","\n","# Initialize arrays for storing the results\n","dice_arr = []\n","iou_arr = []\n","image_count = 0\n","\n","# Loop through all images in the image folder\n","for filename in os.listdir(image_folder):\n","    if filename.endswith(\".png\") or filename.endswith(\".jpg\"):  # Only operate on image files\n","        image_path = os.path.join(image_folder, filename)\n","\n","        # Get the base name of the image (without the extension)\n","        image_base_name = os.path.splitext(filename)[0]\n","\n","        # List all masks that start with the same base name\n","        masks = [mask for mask in os.listdir(gt_folder) if mask.startswith(image_base_name)]\n","\n","        # If no masks are found, skip the image\n","        if not masks:\n","            print(f\"No mask found for {filename}. Skipping...\")\n","            continue\n","\n","        # Process each mask associated with this image\n","        for mask_name in masks:\n","            gt_path = os.path.join(gt_folder, mask_name)\n","            gt = Image.open(gt_path)\n","            gt = np.array(gt.convert(\"L\")) / 255  # Convert to binary (0 or 1)\n","\n","            # Generate prompt\n","            median_x, median_y = find_median_point(gt)\n","            input_point = np.array([[median_y, median_x]])  # Note that it's (y, x)\n","            input_label = np.array([1])\n","\n","            # Get the predicted mask using the segment function\n","            pred_mask = segment(1, input_point, image_path, predictor, show_mask=True)  # 1 stands for Single Point Prompt Type\n","\n","            # Dice Coefficient\n","            dice = dice_coefficient(pred_mask, gt)\n","            print(f\"Dice Coefficient for {filename} (mask {mask_name}): {dice:.4f}\")\n","            dice_arr.append(dice)\n","\n","            # IoU (Intersection over Union)\n","            intersection = np.sum((pred_mask == 1) & (gt == 1))\n","            union = np.sum((pred_mask == 1) | (gt == 1))\n","            iou = intersection / union if union > 0 else 0\n","            print(f\"IoU for {filename} (mask {mask_name}): {iou:.4f}\")\n","            iou_arr.append(iou)\n","\n","        # Increment the image count after processing all masks for this image\n","        image_count += 1\n","\n","        # If we have processed 10 images, stop further processing\n","        #if image_count >= 2:\n","            #break\n","\n","    # If we've processed 10 images, exit the outer loop\n","    #if image_count >= 2:\n","        #break\n","\n","# Calculate and print the averages directly\n","if dice_arr:\n","    print(f\"Mean Dice Coefficient: {np.mean(dice_arr):.4f}\")\n","    print(\"All Dice Coefficients:\", dice_arr)\n","\n","if iou_arr:\n","    print(f\"Mean IoU: {np.mean(iou_arr):.4f}\")\n","    print(\"All IoU values:\", iou_arr)"],"metadata":{"id":"zfnetxr2z1_x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"iueoGJajz2Fy"},"execution_count":null,"outputs":[]}]}