{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyObMBNvYOT3ByGo6n5eP1q6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Jt7wRixLyORT"},"outputs":[],"source":["# import drive files\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["using_colab = True\n","if using_colab:\n","    import torch\n","    import torchvision\n","    print(\"PyTorch version:\", torch.__version__)\n","    print(\"Torchvision version:\", torchvision.__version__)\n","    print(\"CUDA is available:\", torch.cuda.is_available())\n","    import sys\n","    !{sys.executable} -m pip install opencv-python matplotlib\n","    !{sys.executable} -m pip install 'git+https://github.com/facebookresearch/segment-anything-2.git'"],"metadata":{"id":"7gow9Lt6yPgS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#STU TEST\n","image_folder = '/content/drive/MyDrive/DLBreast/SAM2/Different_datasets/STU/labels'  # path of all the test images\n","gt_folder = '/content/drive/MyDrive/DLBreast/SAM2/Different_datasets/STU/masks'  # path of ground truth masks\n","result_folder = '/content/drive/MyDrive/DLBreast/SAM2/Different_datasets/Different_prediction/STU' # path of evaluation result images\n","sam2_checkpoint = \"/content/drive/MyDrive/sam2_hiera_large.pt\"  #checkpoints (coefficients) of the SAM2 model\n","\n","model_cfg = \"sam2_hiera_l.yaml\""],"metadata":{"id":"sdE7pMlMyPij"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","# if using Apple MPS, fall back to CPU for unsupported ops\n","os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n","import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import pandas as pd\n","import random\n","from sam2.build_sam import build_sam2\n","from sam2.sam2_image_predictor import SAM2ImagePredictor\n","\n","# select the device for computation\n","if torch.cuda.is_available():\n","    device = torch.device(\"cuda\")\n","    current_device = torch.cuda.current_device()\n","    print(\"Current GPU device:\", torch.cuda.get_device_name(current_device))\n","elif torch.backends.mps.is_available():\n","    device = torch.device(\"mps\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(f\"using device: {device}\")\n","\n","if device.type == \"cuda\":\n","    # use bfloat16 for the entire notebook\n","    torch.autocast(\"cuda\", dtype=torch.bfloat16).__enter__()\n","    # turn on tfloat32 for Ampere GPUs (https://pytorch.org/docs/stable/notes/cuda.html#tensorfloat-32-tf32-on-ampere-devices)\n","    if torch.cuda.get_device_properties(0).major >= 8:\n","        torch.backends.cuda.matmul.allow_tf32 = True\n","        torch.backends.cudnn.allow_tf32 = True\n","elif device.type == \"mps\":\n","    print(\n","        \"\\nSupport for MPS devices is preliminary. SAM 2 is trained with CUDA and might \"\n","        \"give numerically different outputs and sometimes degraded performance on MPS. \"\n","        \"See e.g. https://github.com/pytorch/pytorch/issues/84936 for a discussion.\"\n","    )\n","\n","# Define functions\n","np.random.seed(3)\n","\n","def show_anns(anns, borders=True):\n","    if len(anns) == 0:\n","        return\n","    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n","    ax = plt.gca()\n","    ax.set_autoscale_on(False)\n","\n","    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n","    img[:, :, 3] = 0\n","    for ann in sorted_anns:\n","        m = ann['segmentation']\n","        color_mask = np.concatenate([np.random.random(3), [0.5]])\n","        img[m] = color_mask\n","        if borders:\n","            import cv2\n","            contours, _ = cv2.findContours(m.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","            contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n","            cv2.drawContours(img, contours, -1, (0, 0, 1, 0.4), thickness=1)\n","    ax.imshow(img)\n","\n","def show_mask(mask, ax, random_color=False, borders=True):\n","    if random_color:\n","        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n","    else:\n","        color = np.array([30/255, 144/255, 255/255, 0.6])\n","    h, w = mask.shape[-2:]\n","    mask = mask.astype(np.uint8)\n","    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n","    if borders:\n","        import cv2\n","        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","        contours = [cv2.approxPolyDP(contour, epsilon=0.01, closed=True) for contour in contours]\n","        mask_image = cv2.drawContours(mask_image, contours, -1, (1, 1, 1, 0.5), thickness=2)\n","    ax.imshow(mask_image)\n","\n","def show_points(coords, labels, ax, marker_size=375):\n","    pos_points = coords[labels==1]\n","    neg_points = coords[labels==0]\n","    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","    ax.scatter(neg_points[:, 0], coords[labels==0][:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n","\n","def show_box(box, ax):\n","    x0, y0 = box[0], box[1]\n","    w, h = box[2] - box[0], box[3] - box[1]\n","    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0, 0, 0, 0), lw=2))\n","\n","def show_masks(image, masks, scores, point_coords=None, box_coords=None, input_labels=None, borders=True):\n","    for i, (mask, score) in enumerate(zip(masks, scores)):\n","        plt.figure(figsize=(5, 5))\n","        plt.imshow(image)\n","        show_mask(mask, plt.gca(), borders=borders)\n","        if point_coords is not None:\n","            assert input_labels is not None\n","            show_points(point_coords, input_labels, plt.gca())\n","        if box_coords is not None:\n","            show_box(box_coords, plt.gca())\n","        if len(scores) > 1:\n","            plt.title(f\"Mask {i+1}, Score: {score:.3f}\", fontsize=18)\n","        plt.axis('off')\n","        plt.show()\n","\n","def threshold_mask(probability_mask, threshold=0.5):\n","    return (probability_mask >= threshold).astype(int)\n","\n","def dice_coefficient(pred_mask, true_mask):\n","    intersection = np.sum(pred_mask * true_mask)\n","    return (2. * intersection) / (np.sum(pred_mask) + np.sum(true_mask))\n","\n","def calculate_iou(binary_mask1, binary_mask2):\n","    intersection = np.logical_and(binary_mask1, binary_mask2).sum()\n","    union = np.logical_or(binary_mask1, binary_mask2).sum()\n","    return 1.0 if union == 0 else intersection / union\n","\n","def find_median_point(gt):\n","    \"\"\"\n","    Encontra o ponto mediano de todos os pixels brancos (região frontal da máscara).\n","\n","    gt: máscara binária (numpy array)\n","\n","    Retorna:\n","    median_x, median_y: coordenadas do ponto mediano\n","    \"\"\"\n","    # Encontra todos os pixels brancos (valor 1)\n","    white_pixels = np.column_stack(np.where(gt == 1))\n","\n","    if len(white_pixels) > 0:\n","        median_x = np.median(white_pixels[:, 0]).astype(int)\n","        median_y = np.median(white_pixels[:, 1]).astype(int)\n","\n","        # Validação para garantir que o ponto está na região branca\n","        if gt[median_x, median_y] == 1:\n","            return median_x, median_y\n","        else:\n","            # Caso a mediana calculada esteja fora da região branca, escolha outro ponto\n","            print(\"A mediana calculada não está na região branca. Selecionando ponto mais próximo.\")\n","            closest_idx = np.argmin(np.linalg.norm(white_pixels - np.array([median_x, median_y]), axis=1))\n","            closest_point = white_pixels[closest_idx]\n","            return closest_point[0], closest_point[1]\n","    else:\n","        raise ValueError(\"Nenhum pixel branco encontrado na máscara.\")\n","\n","\n","def find_rect_box(gt):\n","    # find all white pixels\n","    white_pixels = np.column_stack(np.where(gt == 1))\n","    # find the boundary\n","    if len(white_pixels) > 0:\n","        x_min, y_min = np.min(white_pixels, axis=0)\n","        x_max, y_max = np.max(white_pixels, axis=0)\n","    else:\n","        print(\"invalid mask\")\n","    input_box = np.array([y_min, x_min, y_max, x_max])  # note that is (y,x)\n","    return input_box\n","\n","\n","'''SAM2's segmentation function'''\n","def segment(prompt_type, prompt, image_path, predictor = None, show_mask = False):\n","    # make sure the predictor is set\n","    if predictor is None:\n","        raise ValueError(\"Predictor must be initialized before calling segment function\")\n","\n","    image = Image.open(image_path)\n","    image = np.array(image.convert(\"RGB\"))\n","    predictor.set_image(image)\n","\n","    if prompt_type == 1:  # single point\n","        input_label = np.array([1])\n","        masks, scores, _ = predictor.predict(\n","            point_coords=prompt,\n","            point_labels=input_label,\n","            multimask_output=False,\n","        )\n","        pred_mask = threshold_mask(masks)\n","        if show_mask:\n","            show_masks(image, masks, scores, point_coords=input_point, input_labels=input_label, borders=True)\n","    elif prompt_type == 2:  # single box\n","        masks, scores, _ = predictor.predict(\n","        point_coords=None,\n","        point_labels=None,\n","        box=prompt[None, :],\n","        multimask_output=False,\n","    )\n","        pred_mask = threshold_mask(masks)\n","        if show_mask:\n","            show_masks(image, masks, scores, box_coords=input_box)\n","    return pred_mask"],"metadata":{"id":"oQddTpV8yPli"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XND74MzWyPqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"kM2uZD2byPtz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Vas6bEeeyPwA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"b3Ay5T78yPyt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"RsCmGjeQyP2L"},"execution_count":null,"outputs":[]}]}