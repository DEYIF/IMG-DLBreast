{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DEYIF/IMG-DLBreast/blob/new_resnet/Resnet_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import drive files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWVGh2gfa--R",
        "outputId": "7388b90b-d7a3-4fb0-af9d-4e3ffdf96d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram Averaging"
      ],
      "metadata": {
        "id": "9TPXtTVueu6q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def normalize_image(image):\n",
        "    # Apply histogram equalization for intensity normalization\n",
        "    normalized_image = cv2.equalizeHist(image)\n",
        "    return normalized_image\n",
        "\n",
        "def normalize_dataset(dataset):\n",
        "    normalized_dataset = []\n",
        "    for image in dataset:\n",
        "        normalized_image = normalize_image(image)\n",
        "        normalized_dataset.append(normalized_image)\n",
        "    return normalized_dataset\n",
        "\n",
        "def load_image(file_path):\n",
        "    if file_path.endswith('.png'):\n",
        "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "        print('None')\n",
        "        image = None\n",
        "    return image\n",
        "\n",
        "def load_dataset(directory):\n",
        "    dataset = []\n",
        "    filenames = []\n",
        "    for filename in os.listdir(directory):\n",
        "        file_path = os.path.join(directory, filename)\n",
        "        image = load_image(file_path)\n",
        "        if image is None or image.size == 0:\n",
        "            print(f\"Failed to load image: {file_path}\")\n",
        "        else:\n",
        "            dataset.append(image)\n",
        "            filenames.append(filename)\n",
        "    return dataset, filenames\n",
        "\n",
        "dataset_from_center1, filenames_center1 = load_dataset('/content/drive/MyDrive/Classification/train/mask')\n",
        "\n",
        "\n",
        "normalized_dataset_center1 = normalize_dataset(dataset_from_center1)\n",
        "\n",
        "\n",
        "output_directory = '/content/drive/MyDrive/Classification/train/histogram_output'\n",
        "os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "for image, filename in zip(normalized_dataset_center1, filenames_center1):\n",
        "    output_path = os.path.join(output_directory, filename)\n",
        "    cv2.imwrite(output_path, image)"
      ],
      "metadata": {
        "id": "N9a2-1xeeVRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Import"
      ],
      "metadata": {
        "id": "VjOScDeEj5Hk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import cv2\n",
        "from skimage import io, color\n",
        "from skimage import color as skcolor\n",
        "from torchvision import transforms\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import torchvision.transforms.functional as F"
      ],
      "metadata": {
        "id": "QBh78N69j4Xc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DBTData(Dataset):\n",
        "    def __init__(self, filepath, mode, crop_to=(224,224), resize_to=(256, 256), color=True):\n",
        "        self._crop_to = crop_to\n",
        "        self._resize_to = resize_to\n",
        "        self._color = color\n",
        "        self.mode = mode\n",
        "        self.filepath = filepath\n",
        "\n",
        "        # 根据模式加载对应的 CSV 文件\n",
        "        if mode == \"train\":\n",
        "            df = pd.read_csv(\"/content/drive/MyDrive/1209full_data/label/train.csv\")\n",
        "            filepath = \"/content/drive/MyDrive/1209full_data/train\"\n",
        "        elif mode == \"valid\":\n",
        "            df = pd.read_csv(\"/content/drive/MyDrive/1210_seperate_database/SUSI/validation.csv\")\n",
        "            filepath = \"/content/drive/MyDrive/1210_seperate_database/SUSI/validation\"\n",
        "            #SUSI /content/drive/MyDrive/1210_seperate_database/SUSI/validation.csv\n",
        "            #SUSI /content/drive/MyDrive/1210_seperate_database/SUSI/validation\n",
        "        elif mode == \"test\":\n",
        "            df = pd.read_csv(\"/content/drive/MyDrive/1210_seperate_database/SUSI/validation.csv\")\n",
        "            filepath = \"/content/drive/MyDrive/1210_seperate_database/SUSI/validation\"\n",
        "\n",
        "        # extract label\n",
        "        y = df[\"type\"].values\n",
        "        self.len = len(y)\n",
        "        x = []\n",
        "\n",
        "        # load images\n",
        "        for i in range(self.len):\n",
        "            Slice = df.at[i, \"filename\"]  # 'filename'\n",
        "            image_path = os.path.join(filepath, Slice)\n",
        "\n",
        "            try:\n",
        "                img = mpimg.imread(image_path)\n",
        "                if len(img.shape) == 3:  #  RGB image，transform to grey image\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                x.append(img)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"File {image_path} not found\")\n",
        "                continue\n",
        "\n",
        "        self.x = x\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "#     def divide_by_255(self, x):\n",
        "#         return x / 255.0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        if self._color:\n",
        "            x = skcolor.gray2rgb(x)  #  RGB image\n",
        "        y = self.y[idx]\n",
        "        # CrossEntropyLoss does not expect a one-hot encoded vector, but class indices\n",
        "\n",
        "        def custom_preprocessing(image):\n",
        "          # Apply noise to the image\n",
        "          noisy_image = add_noise_to_image(image)\n",
        "\n",
        "          # Apply blur to the image\n",
        "          blurred_image = apply_blur_to_image(noisy_image)\n",
        "\n",
        "          # Adjust contrast and brightness\n",
        "          enhanced_image = adjust_contrast_brightness(blurred_image)\n",
        "\n",
        "          return enhanced_image\n",
        "\n",
        "        def add_noise_to_image(image):\n",
        "            # Add noise to the image (customize this function as needed)\n",
        "            noisy_image = np.clip(image + np.random.normal(loc=0, scale=0.1, size=image.shape), 0, 1)\n",
        "            return noisy_image\n",
        "\n",
        "        def apply_blur_to_image(image):\n",
        "            # Apply blur to the image (customize this function as needed)\n",
        "            blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "            return blurred_image\n",
        "\n",
        "        def adjust_contrast_brightness(image_tensor):\n",
        "            # Convert PyTorch tensor to PIL image for transformations\n",
        "            pil_img = F.to_pil_image(image_tensor)\n",
        "\n",
        "            # Adjust contrast (factor=1.5)\n",
        "            pil_img = F.adjust_contrast(pil_img, contrast_factor=1.5)\n",
        "\n",
        "            # Adjust brightness (factor=1.2)\n",
        "            pil_img = F.adjust_brightness(pil_img, brightness_factor=1.2)\n",
        "\n",
        "            # Convert PIL image back to PyTorch tensor\n",
        "            enhanced_img_tensor = F.to_tensor(pil_img)\n",
        "\n",
        "            return enhanced_img_tensor\n",
        "\n",
        "\n",
        "        x = np.atleast_3d(x)  # I love numpy!\n",
        "        x = x.astype(np.uint8)\n",
        "        x = Image.fromarray(x.astype(np.uint8))\n",
        "#         trans = transforms.Compose([\n",
        "#             transforms.ToPILImage(),\n",
        "# #             transforms.CenterCrop(self._crop_to),\n",
        "\n",
        "#             transforms.Resize(self._resize_to),\n",
        "#             transforms.ToTensor(),\n",
        "# #             transforms.Grayscale(num_output_channels=1),\n",
        "# #             transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "# #             transforms.Normalize(mean=[0], std=[1/255])\n",
        "# #             self.divide_by_255\n",
        "# #             // %255\n",
        "#         ])\n",
        "#         x = trans(x)\n",
        "        # mean_nums = [.275, .275, .275]\n",
        "        # std_nums = [.197, .197, .197]\n",
        "\n",
        "        # train_transforms = T.Compose([\n",
        "        #   T.Resize([299,299]),\n",
        "        #   T.RandomRotation(degrees=5),\n",
        "        #   T.RandomHorizontalFlip(),\n",
        "        #   T.RandomPerspective(),\n",
        "        #   T.ToTensor(),\n",
        "        #   T.Normalize(mean_nums, std_nums)])\n",
        "\n",
        "        # valid_transforms = T.Compose([\n",
        "        #   T.Resize([299,299]),\n",
        "        #   T.RandomRotation(degrees=5),\n",
        "        #   T.RandomHorizontalFlip(),\n",
        "        #   T.RandomPerspective(),\n",
        "        #   T.ToTensor(),\n",
        "        #   T.Normalize(mean_nums, std_nums)\n",
        "        # ])\n",
        "\n",
        "        # test_transforms = T.Compose([\n",
        "        #   T.Resize([299,299]),\n",
        "        #   T.ToTensor(),\n",
        "        #   T.Normalize(mean_nums, std_nums)\n",
        "        # ])\n",
        "\n",
        "\n",
        "        augmentation_class1 = T.Compose([\n",
        "          T.RandomRotation(degrees=5),\n",
        "          T.RandomHorizontalFlip(p=0.5),\n",
        "          # transforms.RandomResizedCrop(size=(height, width), scale=(0.9, 1.1)),\n",
        "          T.RandomAffine(degrees=5, translate=(0.1, 0.1))\n",
        "          # T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        datagen = T.Compose([\n",
        "          T.RandomHorizontalFlip(p=1.0),  # Always apply horizontal flip\n",
        "          T.RandomVerticalFlip(p=1.0),    # Always apply vertical flip\n",
        "          T.Pad(padding=10, padding_mode='edge') # Fill missing pixels with the nearest value\n",
        "          # T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        test_trans = T.Compose([\n",
        "          T.Resize([299,299]),\n",
        "          T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        # Test transform: Ensure consistency with train and valid\n",
        "        test_transforms = T.Compose([\n",
        "            T.Resize(self._resize_to),  # Resize to the specified dimensions\n",
        "            T.ToTensor(),  # Convert to PyTorch tensor\n",
        "            T.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize for consistency\n",
        "        ])\n",
        "\n",
        "\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            x = train_transforms(x)\n",
        "        elif self.mode == \"valid\":\n",
        "            x = valid_transforms(x)\n",
        "        elif self.mode == \"test\":\n",
        "            x = test_transforms(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):  # return datalength\n",
        "        return self.len\n",
        "\n",
        "# dataset = DBTData('train_phase2')\n",
        "# train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "RVUNjL_jkFYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test部分修改"
      ],
      "metadata": {
        "id": "lnGW_vsDtR7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DBTData(Dataset):\n",
        "    def __init__(self, filepath, mode, crop_to=(224,224), resize_to=(256, 256), color=True):\n",
        "        self._crop_to = crop_to\n",
        "        self._resize_to = resize_to\n",
        "        self._color = color\n",
        "        self.mode = mode\n",
        "        self.filepath = filepath\n",
        "\n",
        "        # 根据模式加载对应的 CSV 文件\n",
        "        if mode == \"train\":\n",
        "            df = pd.read_csv(\"/content/drive/MyDrive/1209full_data/label/train.csv\")\n",
        "            filepath = \"/content/drive/MyDrive/1209full_data/train\"\n",
        "        elif mode == \"valid\":\n",
        "            df = pd.read_csv(\"/content/drive/MyDrive/1210_seperate_database/SUSI/validation.csv\")\n",
        "            filepath = \"/content/drive/MyDrive/1210_seperate_database/SUSI/validation\"\n",
        "            #SUSI /content/drive/MyDrive/1210_seperate_database/SUSI/validation.csv\n",
        "            #SUSI /content/drive/MyDrive/1210_seperate_database/SUSI/validation\n",
        "        elif mode == \"test\":\n",
        "            df = pd.read_csv(\"/content/drive/MyDrive/1210_seperate_database/SUSI/validation.csv\")\n",
        "            filepath = \"/content/drive/MyDrive/1210_seperate_database/SUSI/validation\"\n",
        "\n",
        "        # extract label\n",
        "        y = df[\"type\"].values\n",
        "        self.len = len(y)\n",
        "        x = []\n",
        "\n",
        "        # load images\n",
        "        for i in range(self.len):\n",
        "            Slice = df.at[i, \"filename\"]  # 'filename'\n",
        "            image_path = os.path.join(filepath, Slice)\n",
        "\n",
        "            try:\n",
        "                img = mpimg.imread(image_path)\n",
        "                if len(img.shape) == 3:  #  RGB image，transform to grey image\n",
        "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "                x.append(img)\n",
        "            except FileNotFoundError:\n",
        "                print(f\"File {image_path} not found\")\n",
        "                continue\n",
        "\n",
        "        self.x = x\n",
        "        self.y = torch.from_numpy(y)\n",
        "\n",
        "#     def divide_by_255(self, x):\n",
        "#         return x / 255.0\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x[idx]\n",
        "        if self._color:\n",
        "            x = skcolor.gray2rgb(x)  #  RGB image\n",
        "        y = self.y[idx]\n",
        "        # CrossEntropyLoss does not expect a one-hot encoded vector, but class indices\n",
        "\n",
        "        def custom_preprocessing(image):\n",
        "          # Apply noise to the image\n",
        "          noisy_image = add_noise_to_image(image)\n",
        "\n",
        "          # Apply blur to the image\n",
        "          blurred_image = apply_blur_to_image(noisy_image)\n",
        "\n",
        "          # Adjust contrast and brightness\n",
        "          enhanced_image = adjust_contrast_brightness(blurred_image)\n",
        "\n",
        "          return enhanced_image\n",
        "\n",
        "        def add_noise_to_image(image):\n",
        "            # Add noise to the image (customize this function as needed)\n",
        "            noisy_image = np.clip(image + np.random.normal(loc=0, scale=0.1, size=image.shape), 0, 1)\n",
        "            return noisy_image\n",
        "\n",
        "        def apply_blur_to_image(image):\n",
        "            # Apply blur to the image (customize this function as needed)\n",
        "            blurred_image = cv2.GaussianBlur(image, (5, 5), 0)\n",
        "            return blurred_image\n",
        "\n",
        "        def adjust_contrast_brightness(image_tensor):\n",
        "            # Convert PyTorch tensor to PIL image for transformations\n",
        "            pil_img = F.to_pil_image(image_tensor)\n",
        "\n",
        "            # Adjust contrast (factor=1.5)\n",
        "            pil_img = F.adjust_contrast(pil_img, contrast_factor=1.5)\n",
        "\n",
        "            # Adjust brightness (factor=1.2)\n",
        "            pil_img = F.adjust_brightness(pil_img, brightness_factor=1.2)\n",
        "\n",
        "            # Convert PIL image back to PyTorch tensor\n",
        "            enhanced_img_tensor = F.to_tensor(pil_img)\n",
        "\n",
        "            return enhanced_img_tensor\n",
        "\n",
        "\n",
        "        x = np.atleast_3d(x)  # I love numpy!\n",
        "        x = x.astype(np.uint8)\n",
        "        x = Image.fromarray(x.astype(np.uint8))\n",
        "\n",
        "\n",
        "        augmentation_class1 = T.Compose([\n",
        "          T.RandomRotation(degrees=5),\n",
        "          T.RandomHorizontalFlip(p=0.5),\n",
        "          # transforms.RandomResizedCrop(size=(height, width), scale=(0.9, 1.1)),\n",
        "          T.RandomAffine(degrees=5, translate=(0.1, 0.1))\n",
        "          # T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        datagen = T.Compose([\n",
        "          T.RandomHorizontalFlip(p=1.0),  # Always apply horizontal flip\n",
        "          T.RandomVerticalFlip(p=1.0),    # Always apply vertical flip\n",
        "          T.Pad(padding=10, padding_mode='edge') # Fill missing pixels with the nearest value\n",
        "          # T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        test_trans = T.Compose([\n",
        "          T.Resize([299,299]),\n",
        "          T.ToTensor()\n",
        "        ])\n",
        "\n",
        "        test_transforms = T.Compose([\n",
        "            T.Resize(self._resize_to),  # Resize to the specified dimensions\n",
        "            T.ToTensor(),  # Convert to PyTorch tensor\n",
        "        ])\n",
        "\n",
        "        if self.mode == \"train\":\n",
        "            x = test_trans(x)\n",
        "            x = datagen(x)\n",
        "            if y == 1:  # Check for class 1\n",
        "                x = augmentation_class1(x)\n",
        "        elif self.mode == \"valid\":\n",
        "            x = test_trans(x)\n",
        "        elif self.mode == \"test\":\n",
        "            x = test_transforms(x)\n",
        "\n",
        "\n",
        "        # if self.mode == \"train\":\n",
        "        #     x = train_transforms(x)\n",
        "        # elif self.mode == \"valid\":\n",
        "        #     x = valid_transforms(x)\n",
        "        # elif self.mode == \"test\":\n",
        "        #     x = test_transforms(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):  # return datalength\n",
        "        return self.len\n",
        "\n",
        "# dataset = DBTData('train_phase2')\n",
        "# train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True, num_workers=2)"
      ],
      "metadata": {
        "id": "HxWaNq7RtEmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "test data path"
      ],
      "metadata": {
        "id": "fqF1Izy1fFt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建数据集对象，并传入必要的参数\n",
        "dataset_test = DBTData('train_phase2', 'test', crop_to=(224, 224), resize_to=(256, 256), color=True)\n",
        "\n",
        "# 打印数据集的样本数\n",
        "print(f\"测试样本数量：{len(dataset_test)}\")\n",
        "\n",
        "# 获取第一个样本并打印标签\n",
        "sample_x, sample_y = dataset_test[0]\n",
        "print(f\"第一个样本的标签：{sample_y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMU9FUYlfE-E",
        "outputId": "492bd8fb-2ca3-4543-c51a-beb1cd71d7d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "测试样本数量：125\n",
            "第一个样本的标签：0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train"
      ],
      "metadata": {
        "id": "-2WdZhhnuZ-p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVxrEdQkYK68",
        "outputId": "d8630b9e-26ee-49fd-b36b-c6682101b489"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "\n",
        "import matplotlib\n",
        "matplotlib.use('Agg')  # headless plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "# from models import BaselineResNet, BayesianResNet\n",
        "import torchvision.models as models\n",
        "from torch.utils.data import DataLoader,random_split\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import argparse\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "#add path\n",
        "sys.path.append('/content/drive/MyDrive/1209run')\n",
        "\n",
        "#import package above\n",
        "from dataImport import DBTData\n",
        "from utils import accuracy\n",
        "\n",
        "!pip install tensorboardX\n",
        "from tensorboardX import SummaryWriter\n",
        "import os\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enable cuda if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# setup tensorboardx\n",
        "writer = SummaryWriter()\n",
        "\n",
        "# dimension properties\n",
        "batch_size = 10\n",
        "val_batch_size = batch_size\n",
        "num_workers = 0\n",
        "num_classes = 2\n",
        "lambda_prop = 0.01\n",
        "\n",
        "# load data\n",
        "# load data\n",
        "color = True\n",
        "resize_to = (256, 256)\n",
        "dataset_train = DBTData('train_phase2','train',crop_to=(224,224), resize_to=resize_to, color=color)\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=num_workers)\n",
        "dataset_valid = DBTData('train_phase2','valid',crop_to=(512,512), resize_to=resize_to, color=color)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=val_batch_size, num_workers=num_workers)\n",
        "\n",
        "assert len(dataset_train) > 0\n",
        "assert len(dataset_valid) > 0\n",
        "print(\"Train dataset length:\", len(dataset_train))\n",
        "print(\"Valid dataset length:\", len(dataset_valid))\n",
        "print('')\n",
        "\n",
        "# create a model\n",
        "model = torch.nn.Module()\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4,betas=(0.9, 0.999),weight_decay=1e-8)\n",
        "lr_scheduler = ReduceLROnPlateau(optimizer, patience=5)\n",
        "\n",
        "# create loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "print('')  # print empty line before training output\n",
        "\n",
        "# save accuracies and losses during training\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "valid_losses = []\n",
        "valid_accuracies = []\n",
        "\n",
        "start_epoch = 0\n",
        "epochs = 100\n",
        "e = 0\n",
        "batch_counter = 0\n",
        "batch_counter_valid = 0\n",
        "\n",
        "for e in range(start_epoch, epochs):\n",
        "\n",
        "    # go through training set\n",
        "    model.train()\n",
        "    print(\"lr =\", optimizer.param_groups[0]['lr'])\n",
        "\n",
        "    epoch_train_loss = []\n",
        "    epoch_train_acc = []\n",
        "    is_best = False\n",
        "\n",
        "    x, y, y_pred = None, None, None\n",
        "    batches = tqdm.tqdm(dataloader_train)\n",
        "    for x, y in batches:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        y_pred = model(x)\n",
        "        train_loss = criterion(y_pred, y)\n",
        "\n",
        "        train_loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print current loss\n",
        "        batches.set_description(\"loss: {:4f}\".format(train_loss.item()))\n",
        "\n",
        "        # sum epoch loss\n",
        "        epoch_train_loss.append(train_loss.item())\n",
        "\n",
        "        # calculate batch train accuracy\n",
        "        batch_acc = accuracy(y_pred, y)\n",
        "        epoch_train_acc.append(batch_acc)\n",
        "\n",
        "        writer.add_scalar('data/train_loss', train_loss.item(), batch_counter)\n",
        "        writer.add_scalar('data/train_acc', batch_acc, batch_counter)\n",
        "        batch_counter += 1\n",
        "\n",
        "    epoch_train_loss = np.mean(epoch_train_loss)\n",
        "    epoch_train_acc = np.mean(epoch_train_acc)\n",
        "    lr_scheduler.step(epoch_train_loss)\n",
        "\n",
        "    # go through validation set\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "\n",
        "        epoch_valid_loss = []\n",
        "        epoch_valid_acc = []\n",
        "\n",
        "        batches = tqdm.tqdm(dataloader_valid)\n",
        "        for x, y in batches:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "\n",
        "            y_pred = model(x)\n",
        "            valid_loss = criterion(y_pred, y)\n",
        "\n",
        "            # print current loss\n",
        "            batches.set_description(\"loss: {:4f}\".format(valid_loss.item()))\n",
        "\n",
        "            # sum epoch loss\n",
        "            epoch_valid_loss.append(valid_loss.item())\n",
        "\n",
        "            # calculate batch train accuracy\n",
        "            batch_acc = accuracy(y_pred, y)\n",
        "            epoch_valid_acc.append(batch_acc)\n",
        "\n",
        "            writer.add_scalar('data/valid_classifier_loss', valid_loss.item(), batch_counter_valid)\n",
        "            writer.add_scalar('data/valid_acc', batch_acc, batch_counter_valid)\n",
        "            batch_counter_valid += 1\n",
        "\n",
        "    epoch_valid_loss = np.mean(epoch_valid_loss)\n",
        "    epoch_valid_acc = np.mean(epoch_valid_acc)\n",
        "\n",
        "    print(\"Epoch {:d}: loss: {:4f}, acc: {:4f}, val_loss: {:4f}, val_acc: {:4f}\"\n",
        "          .format(e,\n",
        "                  epoch_train_loss,\n",
        "                  epoch_train_acc,\n",
        "                  epoch_valid_loss,\n",
        "                  epoch_valid_acc,\n",
        "                  ))\n",
        "\n",
        "    # save epoch losses\n",
        "    train_losses.append(epoch_train_loss)\n",
        "    train_accuracies.append(epoch_train_acc)\n",
        "    valid_losses.append(epoch_valid_loss)\n",
        "    valid_accuracies.append(epoch_valid_acc)\n",
        "\n",
        "    if valid_losses[-1] <= np.min(valid_losses):\n",
        "        is_best = True\n",
        "\n",
        "    if is_best:\n",
        "        filename = \"/content/drive/MyDrive/1210_seperate_database/SUSI/snapshots\" + \"_best.pth.tar\"\n",
        "        print(\"Saving best weights so far with val_loss: {:4f}\".format(valid_losses[-1]))\n",
        "        torch.save({\n",
        "            'epoch': e,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'train_losses': train_losses,\n",
        "            'train_accs': train_accuracies,\n",
        "            'val_losses': valid_losses,\n",
        "            'val_accs': valid_accuracies,\n",
        "        }, filename)\n",
        "\n",
        "    if e == epochs-1:\n",
        "      #define Google Drive path folder\n",
        "        import os\n",
        "        from google.colab import drive\n",
        "\n",
        "        #Google Drive\n",
        "        drive.mount('/content/drive')\n",
        "\n",
        "        #define Google Drive path folder\n",
        "        filename = \"/content/drive/MyDrive/1210_seperate_database/SUSI/trainmodels\" + \"_\" + str(e) + \".pth.tar\"\n",
        "        print(\"Saving weights at epoch {:d}\".format(e))\n",
        "        torch.save({\n",
        "            'epoch': e,\n",
        "            'state_dict': model.state_dict(),\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'train_losses': train_losses,\n",
        "            'train_accs': train_accuracies,\n",
        "            'val_losses': valid_losses,\n",
        "            'val_accs': valid_accuracies,\n",
        "            }, filename)\n",
        "\n",
        "    print('')\n",
        "\n",
        "    # plot losses\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(train_losses)), train_losses, marker='x')\n",
        "    plt.plot(range(len(valid_losses)), valid_losses, marker='x')\n",
        "    plt.title(\"loss\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"loss\")\n",
        "\n",
        "    plt.savefig(\"_loss.pdf\", dpi=300)\n",
        "    plt.figure()\n",
        "    plt.plot(range(len(train_accuracies)), train_accuracies, marker='x')\n",
        "    plt.plot(range(len(valid_accuracies)), valid_accuracies, marker='x')\n",
        "    plt.title(\"accuracy\")\n",
        "    plt.xlabel(\"epoch\")\n",
        "    plt.ylabel(\"acc\")\n",
        "    plt.savefig(\"acc.pdf\", dpi=300)\n",
        "    plt.close('all')"
      ],
      "metadata": {
        "id": "D8NfC95ExhA2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "outputId": "715a6b1b-9a5b-4dbb-f979-4b84c3d092b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset length: 2492\n",
            "Valid dataset length: 278\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "lr = 0.0001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss: 0.713948:  76%|███████▌  | 190/250 [00:58<00:18,  3.22it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-7bbe88340a0c>\u001b[0m in \u001b[0;36m<cell line: 56>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;31m# print current loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mbatches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss: {:4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;31m# sum epoch loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test"
      ],
      "metadata": {
        "id": "-qevUNwZKcpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# Max-Heinrich Laves\n",
        "# Institute of Mechatronic Systems\n",
        "# Leibniz Universität Hannover, Germany\n",
        "# 2019\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from sklearn import metrics\n",
        "\n",
        "torch.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.models as models\n",
        "import argparse\n",
        "import tqdm\n",
        "\n",
        "#add path\n",
        "sys.path.append('/content/drive/MyDrive/1209run')\n",
        "\n",
        "from dataImport import DBTData\n",
        "from utils import accuracy\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.metrics import classification_report, f1_score, recall_score\n",
        "from torchvision.models import shufflenet_v2_x1_0\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import tqdm\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "4n49oUiJKaR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建数据集对象，并传入必要的参数\n",
        "dataset_test = DBTData('train_phase2', 'test', crop_to=(224, 224), resize_to=(256, 256), color=True)\n",
        "\n",
        "# 打印数据集的样本数\n",
        "print(f\"测试样本数量：{len(dataset_test)}\")\n",
        "\n",
        "# 获取第一个样本并打印标签\n",
        "sample_x, sample_y = dataset_test[0]\n",
        "print(f\"第一个样本的标签：{sample_y}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddt28vOzdg3x",
        "outputId": "aee73120-1243-4ff7-b947-2379ccde4eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "测试样本数量：278\n",
            "第一个样本的标签：0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataloader_test = DataLoader(dataset_test, batch_size=val_batch_size, shuffle=False)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, (x, y) in enumerate(dataloader_test):\n",
        "        print(f\"Batch {i}: x={type(x)}, y={type(y)}\")  # Debugging\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        y_pred = model(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "cdxB3hrczKex",
        "outputId": "de080d6b-aca3-40ce-86dd-585ea8aa779e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-5d6159a4095f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch {i}: x={type(x)}, y={type(y)}\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Debugging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    396\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Handle `CustomType` automatically\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \"\"\"\n\u001b[0;32m--> 398\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_collate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             return [\n\u001b[0m\u001b[1;32m    212\u001b[0m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             return [\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollate_fn_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m             ]  # Backwards compatibility.\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch, collate_fn_map)\u001b[0m\n\u001b[1;32m    238\u001b[0m                 ]\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate_err_msg_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class 'PIL.Image.Image'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# enable cuda if available\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# properties\n",
        "batch_size = 10\n",
        "val_batch_size = 1\n",
        "num_classes = 2\n",
        "num_mc = 50\n",
        "\n",
        "# load data\n",
        "color = True\n",
        "resize_to = (256, 256)\n",
        "color = True\n",
        "resize_to = (256, 256)\n",
        "snapshot=\"/content/drive/MyDrive/1209run/snapshots_best.pth.tar\"\n",
        "dataset_test = DBTData('train_phase2',\"valid\",crop_to=(224,224), resize_to=resize_to, color=color)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=val_batch_size, shuffle=False)\n",
        "\n",
        "assert len(dataset_test) > 0\n",
        "\n",
        "print(\"Test dataset length:\", len(dataset_test))\n",
        "print('')\n",
        "\n",
        "# create a model\n",
        "model = torch.nn.Module()\n",
        "model = models.resnet50(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = torch.nn.Linear(num_ftrs, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "# load weights for flow estimation from best last stage\n",
        "checkpoint = torch.load(snapshot, map_location=device)\n",
        "print(\"Loading previous weights at epoch \" + str(checkpoint['epoch']) + \" from \" + snapshot)\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "# Create loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Go through test set\n",
        "print(\"Going through test set.\")\n",
        "model.eval()\n",
        "y_true_np = []\n",
        "y_pred_np = []\n",
        "y_pred_prob_np = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "    correct_var = []\n",
        "    incorrect_var = []\n",
        "\n",
        "    batches = tqdm.tqdm(dataloader_test)\n",
        "    for i, (x, y) in enumerate(batches):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        y_pred = model(x)\n",
        "\n",
        "        # Use softmax to get the predicted probabilities\n",
        "        y_pred_prob = F.softmax(y_pred, dim=1)\n",
        "\n",
        "        y_true_np.append(y.data.cpu().numpy())\n",
        "        y_pred_np.append(y_pred_prob.argmax(dim=1).data.cpu().numpy())\n",
        "        y_pred_prob_np.append(y_pred_prob.data.cpu().numpy())\n",
        "\n",
        "        y = y.to(torch.long)\n",
        "        mean = y_pred_prob.to(torch.float32)\n",
        "\n",
        "        test_loss = criterion(mean, y)\n",
        "        test_losses.append(test_loss.item())\n",
        "\n",
        "print(\"test mean loss:\", np.mean(test_losses))\n",
        "\n",
        "y_pred_np = np.array(y_pred_np).squeeze()\n",
        "y_true_np = np.array(y_true_np).squeeze()\n",
        "y_pred_prob_np = np.array(y_pred_prob_np).squeeze()\n",
        "\n",
        "# Save the prediction probabilities\n",
        "np.save(\"mc_output_\" + str(num_mc) + \"_probabilities\" + \".npy\", y_pred_prob_np)\n",
        "\n",
        "# Calculate weighted F1 score\n",
        "f1 = f1_score(y_true_np, y_pred_np, average='weighted')\n",
        "print(\"Weighted F1 score:\", f1)\n",
        "\n",
        "# Calculate weighted recall\n",
        "recall = recall_score(y_true_np, y_pred_np, average='weighted')\n",
        "print(\"Weighted recall:\", recall)\n",
        "\n",
        "# Compute AUC for each class\n",
        "unique_classes = np.unique(y_true_np)\n",
        "\n",
        "if len(unique_classes) > 1:\n",
        "    try:\n",
        "        # Compute AUC score\n",
        "        auc_score = roc_auc_score(y_true_np, y_pred_prob_np[:, 1], average='weighted')\n",
        "        print(\"AUC:\", auc_score)\n",
        "\n",
        "        # --- Add ROC Curve Calculation and Plotting ---\n",
        "        fpr, tpr, thresholds = roc_curve(y_true_np, y_pred_prob_np[:, 1])  # Compute ROC values\n",
        "        roc_auc = auc(fpr, tpr)  # Compute the area under the curve (AUC)\n",
        "\n",
        "        # Plot ROC curve\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', linestyle='--', label='Random Guess')\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('BUSBRA_Receiver Operating Characteristic (ROC)')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.savefig(\"BUSBRA_ROC_Curve.pdf\", dpi=300)  # Save the plot\n",
        "        plt.show()\n",
        "        print(\"ROC curve plotted and saved.\")\n",
        "    except ValueError as e:\n",
        "        print(f\"Error in computing AUC or plotting ROC curve: {e}\")\n",
        "else:\n",
        "    print(f\"AUC cannot be computed because y_true contains only one class: {unique_classes}\")\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true_np, y_pred_np)\n",
        "print(conf_matrix)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"Actual Labels\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.savefig(\"Confusion Matrix.pdf\", dpi=300)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5HNSI5gKgMD",
        "outputId": "5a18dc40-014a-46a9-fd89-830d2749173b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset length: 278\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-6-eab702e42e14>:32: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(snapshot, map_location=device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading previous weights at epoch 15 from /content/drive/MyDrive/1209run/snapshots_best.pth.tar\n",
            "Going through test set.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 278/278 [00:04<00:00, 58.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test mean loss: 0.5440681664634952\n",
            "Weighted F1 score: 0.7652524701916448\n",
            "Weighted recall: 0.7661870503597122\n",
            "AUC: 0.8179324440619621\n",
            "ROC curve plotted and saved.\n",
            "[[136  30]\n",
            " [ 35  77]]\n"
          ]
        }
      ]
    }
  ]
}